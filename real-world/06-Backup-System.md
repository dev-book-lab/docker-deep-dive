# 06. Backup System - ÏûêÎèô Î∞±ÏóÖ ÏãúÏä§ÌÖú

## üéØ Ïù¥ Ï±ïÌÑ∞ÏóêÏÑú Î∞∞Ïö∏ Í≤É

- **Database Î∞±ÏóÖ**: PostgreSQL, MySQL, MongoDB
- **Volume Î∞±ÏóÖ**: Docker Volume Î∞±ÏóÖ
- **ÏûêÎèôÌôî**: Cron, Backup Scheduler
- **Î≥µÍµ¨ Ï†ÑÎûµ**: Point-in-time Recovery
- **ÏõêÍ≤© Î∞±ÏóÖ**: S3, Cloud Storage
- **Ïã§Ï†Ñ Íµ¨ÏÑ±**: Production-ready Î∞±ÏóÖ

## üìå Ïôú Ï§ëÏöîÌïúÍ∞Ä?

**"Î∞±ÏóÖÏù¥ ÏóÜÎäî ÌîÑÎ°úÎçïÏÖòÏùÄ ÏãúÌïúÌè≠ÌÉÑÍ≥º Í∞ôÏäµÎãàÎã§."**

```
BackupÏùò Ï§ëÏöîÏÑ±:

Without Backup:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ÏÇ¨Í≥† Î∞úÏÉù (ÏÑúÎ≤Ñ Ïû•Ïï†, Ïã§ÏàòÎ°ú ÏÇ≠Ï†ú, ÎûúÏÑ¨Ïõ®Ïñ¥)             ‚îÇ
‚îÇ   ‚Üì                                             ‚îÇ
‚îÇ Îç∞Ïù¥ÌÑ∞ ÏÜêÏã§ üí•                                    ‚îÇ
‚îÇ   ‚Üì                                             ‚îÇ
‚îÇ Î≥µÍµ¨ Î∂àÍ∞ÄÎä• ‚ùå                                     ‚îÇ
‚îÇ   ‚Üì                                             ‚îÇ
‚îÇ ÎπÑÏ¶àÎãàÏä§ Ï§ëÎã®                                      ‚îÇ
‚îÇ Í≥†Í∞ù Ïã†Î¢∞ ÏÉÅÏã§                                     ‚îÇ
‚îÇ Î≤ïÏ†Å Î¨∏Ï†ú                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

With Backup:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ÏÇ¨Í≥† Î∞úÏÉù                                         ‚îÇ
‚îÇ   ‚Üì                                             ‚îÇ
‚îÇ Î∞±ÏóÖÏóêÏÑú Î≥µÍµ¨ (1ÏãúÍ∞Ñ Ï†Ñ Îç∞Ïù¥ÌÑ∞)                        ‚îÇ
‚îÇ   ‚Üì                                             ‚îÇ
‚îÇ ÏÑúÎπÑÏä§ Ïû¨Í∞ú ‚úÖ                                     ‚îÇ
‚îÇ   ‚Üì                                             ‚îÇ
‚îÇ ÏµúÏÜåÌïúÏùò Îç∞Ïù¥ÌÑ∞ ÏÜêÏã§                                 ‚îÇ
‚îÇ ÎπÑÏ¶àÎãàÏä§ Ïó∞ÏÜçÏÑ± Ïú†ÏßÄ                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Backup Strategy (3-2-1 Rule):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3-2-1 Backup Rule                               ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ 3: Îç∞Ïù¥ÌÑ∞Î•º 3Í∞ú Î≥µÏÇ¨Î≥∏ÏúºÎ°ú Ïú†ÏßÄ                        ‚îÇ
‚îÇ    - Original (Ïö¥ÏòÅ)                             ‚îÇ
‚îÇ    - Local Backup (Î°úÏª¨ ÏÑúÎ≤Ñ)                     ‚îÇ
‚îÇ    - Remote Backup (ÌÅ¥ÎùºÏö∞Îìú)                     ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ 2: 2Í∞úÏùò Îã§Î•∏ ÎØ∏ÎîîÏñ¥Ïóê Ï†ÄÏû•                           ‚îÇ
‚îÇ    - Local Disk                                 ‚îÇ
‚îÇ    - Cloud Storage (S3, GCS)                    ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ 1: 1Í∞úÎäî Ïò§ÌîÑÏÇ¨Ïù¥Ìä∏ (ÏõêÍ≤©ÏßÄ)                          ‚îÇ
‚îÇ    - Îã§Î•∏ ÏßÄÏó≠Ïùò Îç∞Ïù¥ÌÑ∞ÏÑºÌÑ∞                           ‚îÇ
‚îÇ    - ÌôîÏû¨, Ïπ®Ïàò Îì± Î¨ºÎ¶¨Ï†Å Ïû¨Ìï¥ ÎåÄÎπÑ                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Backup Architecture:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ
‚îÇ  ‚îÇ  Production  ‚îÇ                               ‚îÇ
‚îÇ  ‚îÇ   Database   ‚îÇ                               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ
‚îÇ         ‚îÇ                                       ‚îÇ
‚îÇ         ‚îÇ (Daily Backup)                        ‚îÇ
‚îÇ         ‚ñº                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ
‚îÇ  ‚îÇ    Local     ‚îÇ                               ‚îÇ
‚îÇ  ‚îÇ   Backup     ‚îÇ ‚Üê Îπ†Î•∏ Î≥µÍµ¨ (RPO: 1Ïùº)           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ
‚îÇ         ‚îÇ                                       ‚îÇ
‚îÇ         ‚îÇ (Sync to Cloud)                       ‚îÇ
‚îÇ         ‚ñº                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ
‚îÇ  ‚îÇ  S3/Cloud    ‚îÇ                               ‚îÇ
‚îÇ  ‚îÇ   Backup     ‚îÇ ‚Üê Ïû•Í∏∞ Î≥¥Í¥Ä, Ïû¨Ìï¥ Î≥µÍµ¨            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Retention Policy:                              ‚îÇ
‚îÇ  - Daily: 7Ïùº                                   ‚îÇ
‚îÇ  - Weekly: 4Ï£º                                  ‚îÇ
‚îÇ  - Monthly: 12Í∞úÏõî                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Key Concepts:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ RPO (Recovery Point Objective)                  ‚îÇ
‚îÇ  - ÏÜêÏã§ Í∞ÄÎä•Ìïú Îç∞Ïù¥ÌÑ∞Ïùò ÏµúÎåÄ ÏãúÍ∞Ñ                      ‚îÇ
‚îÇ  - Ïòà: RPO 1ÏãúÍ∞Ñ ‚Üí ÏµúÎåÄ 1ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞ ÏÜêÏã§              ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ RTO (Recovery Time Objective)                   ‚îÇ
‚îÇ  - Î≥µÍµ¨Ïóê Í±∏Î¶¨Îäî ÏµúÎåÄ ÏãúÍ∞Ñ                            ‚îÇ
‚îÇ  - Ïòà: RTO 4ÏãúÍ∞Ñ ‚Üí 4ÏãúÍ∞Ñ ÎÇ¥ ÏÑúÎπÑÏä§ Ïû¨Í∞ú               ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ Full Backup:                                    ‚îÇ
‚îÇ  - Î™®Îì† Îç∞Ïù¥ÌÑ∞ Î∞±ÏóÖ                                 ‚îÇ
‚îÇ  - ÏãúÍ∞Ñ Ïò§Îûò Í±∏Î¶º                                   ‚îÇ
‚îÇ  - Î≥µÍµ¨ Îπ†Î¶Ñ                                       ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ Incremental Backup:                             ‚îÇ
‚îÇ  - Î≥ÄÍ≤ΩÎêú Îç∞Ïù¥ÌÑ∞Îßå Î∞±ÏóÖ                              ‚îÇ
‚îÇ  - ÏãúÍ∞Ñ ÏßßÏùå                                      ‚îÇ
‚îÇ  - Î≥µÍµ¨ ÎäêÎ¶º (Full + Î™®Îì† Incremental)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Ïã§Î¨¥ ÏòÅÌñ•:**
- **Ïû¨Ìï¥ Î≥µÍµ¨**: Îç∞Ïù¥ÌÑ∞ ÏÜêÏã§ Î∞©ÏßÄ
- **Í∑úÏ†ï Ï§ÄÏàò**: Î≤ïÏ†Å ÏöîÍµ¨ÏÇ¨Ìï≠ Ï∂©Ï°±
- **ÎπÑÏ¶àÎãàÏä§ Ïó∞ÏÜçÏÑ±**: ÏÑúÎπÑÏä§ Ï§ëÎã® ÏµúÏÜåÌôî
- **ÏïàÏã¨**: Ïñ∏Ï†úÎì† Î≥µÍµ¨ Í∞ÄÎä•

---

## üîß Ïã§Ïäµ 1: PostgreSQL Î∞±ÏóÖ

### Step 1: Í∏∞Î≥∏ Î∞±ÏóÖ Ïä§ÌÅ¨Î¶ΩÌä∏

```bash
#!/bin/bash
# backup-postgres.sh

# ÏÑ§Ï†ï
DB_HOST="postgres"
DB_PORT="5432"
DB_NAME="mydb"
DB_USER="myuser"
DB_PASSWORD="mypassword"
BACKUP_DIR="/backups/postgres"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/postgres_${DB_NAME}_${TIMESTAMP}.sql"

# ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
mkdir -p ${BACKUP_DIR}

# Î∞±ÏóÖ Ïã§Ìñâ
echo "Starting backup: ${BACKUP_FILE}"
PGPASSWORD=${DB_PASSWORD} pg_dump \
  -h ${DB_HOST} \
  -p ${DB_PORT} \
  -U ${DB_USER} \
  -d ${DB_NAME} \
  -F c \
  -b \
  -v \
  -f ${BACKUP_FILE}

# ÏïïÏ∂ï
gzip ${BACKUP_FILE}
BACKUP_FILE="${BACKUP_FILE}.gz"

# Í≤∞Í≥º ÌôïÏù∏
if [ $? -eq 0 ]; then
  SIZE=$(du -h ${BACKUP_FILE} | cut -f1)
  echo "‚úÖ Backup completed: ${BACKUP_FILE} (${SIZE})"
else
  echo "‚ùå Backup failed"
  exit 1
fi

# Ïò§ÎûòÎêú Î∞±ÏóÖ ÏÇ≠Ï†ú (7Ïùº Ïù¥ÏÉÅ)
find ${BACKUP_DIR} -name "*.sql.gz" -mtime +7 -delete
echo "üóëÔ∏è  Cleaned up old backups (>7 days)"

# Î∞±ÏóÖ Í≤ÄÏ¶ù
gunzip -t ${BACKUP_FILE}
if [ $? -eq 0 ]; then
  echo "‚úÖ Backup file is valid"
else
  echo "‚ùå Backup file is corrupted"
  exit 1
fi
```

### Step 2: Docker Compose with Backup

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    restart: always
    environment:
      POSTGRES_DB: mydb
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - app

  # Backup Container
  postgres-backup:
    image: postgres:15-alpine
    container_name: postgres-backup
    restart: always
    volumes:
      - ./backup-scripts:/scripts
      - ./backups:/backups
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=mydb
      - DB_USER=myuser
      - DB_PASSWORD=mypassword
    command: >
      sh -c "
      while true; do
        echo 'Running backup at' \$(date)
        /scripts/backup-postgres.sh
        echo 'Next backup in 24 hours'
        sleep 86400
      done
      "
    depends_on:
      - postgres
    networks:
      - app

volumes:
  postgres_data:

networks:
  app:
    driver: bridge
```

### Step 3: Î≥µÍµ¨ Ïä§ÌÅ¨Î¶ΩÌä∏

```bash
#!/bin/bash
# restore-postgres.sh

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
  echo "Usage: $0 <backup_file.sql.gz>"
  exit 1
fi

if [ ! -f "$BACKUP_FILE" ]; then
  echo "Error: Backup file not found: $BACKUP_FILE"
  exit 1
fi

# ÏïïÏ∂ï Ìï¥Ï†ú
gunzip -c ${BACKUP_FILE} > /tmp/restore.sql

# Î≥µÍµ¨ Ï†Ñ ÌôïÏù∏
echo "‚ö†Ô∏è  WARNING: This will restore the database"
echo "Backup file: ${BACKUP_FILE}"
echo "Database: ${DB_NAME}"
read -p "Continue? (yes/no): " confirm

if [ "$confirm" != "yes" ]; then
  echo "Aborted"
  exit 0
fi

# Í∏∞Ï°¥ Ïó∞Í≤∞ Ï¢ÖÎ£å
PGPASSWORD=${DB_PASSWORD} psql \
  -h ${DB_HOST} \
  -U ${DB_USER} \
  -d postgres \
  -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname='${DB_NAME}';"

# Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÇ≠Ï†ú Î∞è Ïû¨ÏÉùÏÑ±
PGPASSWORD=${DB_PASSWORD} psql \
  -h ${DB_HOST} \
  -U ${DB_USER} \
  -d postgres \
  -c "DROP DATABASE IF EXISTS ${DB_NAME};"

PGPASSWORD=${DB_PASSWORD} psql \
  -h ${DB_HOST} \
  -U ${DB_USER} \
  -d postgres \
  -c "CREATE DATABASE ${DB_NAME};"

# Î≥µÍµ¨
PGPASSWORD=${DB_PASSWORD} pg_restore \
  -h ${DB_HOST} \
  -p ${DB_PORT} \
  -U ${DB_USER} \
  -d ${DB_NAME} \
  -v \
  /tmp/restore.sql

if [ $? -eq 0 ]; then
  echo "‚úÖ Restore completed"
else
  echo "‚ùå Restore failed"
  exit 1
fi

# ÏûÑÏãú ÌååÏùº ÏÇ≠Ï†ú
rm /tmp/restore.sql
```

---

## üîß Ïã§Ïäµ 2: MySQL Î∞±ÏóÖ

### Step 1: MySQL Î∞±ÏóÖ Ïä§ÌÅ¨Î¶ΩÌä∏

```bash
#!/bin/bash
# backup-mysql.sh

# ÏÑ§Ï†ï
DB_HOST="mysql"
DB_PORT="3306"
DB_NAME="mydb"
DB_USER="myuser"
DB_PASSWORD="mypassword"
BACKUP_DIR="/backups/mysql"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/mysql_${DB_NAME}_${TIMESTAMP}.sql"

mkdir -p ${BACKUP_DIR}

# Î∞±ÏóÖ Ïã§Ìñâ
echo "Starting MySQL backup: ${BACKUP_FILE}"
mysqldump \
  -h ${DB_HOST} \
  -P ${DB_PORT} \
  -u ${DB_USER} \
  -p${DB_PASSWORD} \
  --single-transaction \
  --routines \
  --triggers \
  --events \
  ${DB_NAME} > ${BACKUP_FILE}

# ÏïïÏ∂ï
gzip ${BACKUP_FILE}
BACKUP_FILE="${BACKUP_FILE}.gz"

if [ $? -eq 0 ]; then
  SIZE=$(du -h ${BACKUP_FILE} | cut -f1)
  echo "‚úÖ MySQL backup completed: ${BACKUP_FILE} (${SIZE})"
else
  echo "‚ùå MySQL backup failed"
  exit 1
fi

# Ïò§ÎûòÎêú Î∞±ÏóÖ ÏÇ≠Ï†ú
find ${BACKUP_DIR} -name "*.sql.gz" -mtime +7 -delete
```

### Step 2: MySQL Î≥µÍµ¨

```bash
#!/bin/bash
# restore-mysql.sh

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
  echo "Usage: $0 <backup_file.sql.gz>"
  exit 1
fi

# ÏïïÏ∂ï Ìï¥Ï†ú Î∞è Î≥µÍµ¨
gunzip -c ${BACKUP_FILE} | mysql \
  -h ${DB_HOST} \
  -P ${DB_PORT} \
  -u ${DB_USER} \
  -p${DB_PASSWORD} \
  ${DB_NAME}

if [ $? -eq 0 ]; then
  echo "‚úÖ MySQL restore completed"
else
  echo "‚ùå MySQL restore failed"
  exit 1
fi
```

---

## üîß Ïã§Ïäµ 3: MongoDB Î∞±ÏóÖ

### Step 1: MongoDB Î∞±ÏóÖ

```bash
#!/bin/bash
# backup-mongodb.sh

# ÏÑ§Ï†ï
MONGO_HOST="mongodb"
MONGO_PORT="27017"
MONGO_USER="root"
MONGO_PASSWORD="rootpassword"
MONGO_DB="mydb"
BACKUP_DIR="/backups/mongodb"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_PATH="${BACKUP_DIR}/mongodb_${TIMESTAMP}"

mkdir -p ${BACKUP_DIR}

# Î∞±ÏóÖ Ïã§Ìñâ
echo "Starting MongoDB backup: ${BACKUP_PATH}"
mongodump \
  --host ${MONGO_HOST} \
  --port ${MONGO_PORT} \
  --username ${MONGO_USER} \
  --password ${MONGO_PASSWORD} \
  --authenticationDatabase admin \
  --db ${MONGO_DB} \
  --out ${BACKUP_PATH}

# ÏïïÏ∂ï
tar -czf ${BACKUP_PATH}.tar.gz -C ${BACKUP_DIR} $(basename ${BACKUP_PATH})
rm -rf ${BACKUP_PATH}

if [ $? -eq 0 ]; then
  SIZE=$(du -h ${BACKUP_PATH}.tar.gz | cut -f1)
  echo "‚úÖ MongoDB backup completed: ${BACKUP_PATH}.tar.gz (${SIZE})"
else
  echo "‚ùå MongoDB backup failed"
  exit 1
fi

# Ïò§ÎûòÎêú Î∞±ÏóÖ ÏÇ≠Ï†ú
find ${BACKUP_DIR} -name "*.tar.gz" -mtime +7 -delete
```

### Step 2: MongoDB Î≥µÍµ¨

```bash
#!/bin/bash
# restore-mongodb.sh

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
  echo "Usage: $0 <backup_file.tar.gz>"
  exit 1
fi

# ÏïïÏ∂ï Ìï¥Ï†ú
TEMP_DIR="/tmp/mongodb_restore"
mkdir -p ${TEMP_DIR}
tar -xzf ${BACKUP_FILE} -C ${TEMP_DIR}

# Î≥µÍµ¨
mongorestore \
  --host ${MONGO_HOST} \
  --port ${MONGO_PORT} \
  --username ${MONGO_USER} \
  --password ${MONGO_PASSWORD} \
  --authenticationDatabase admin \
  --db ${MONGO_DB} \
  --drop \
  ${TEMP_DIR}/$(ls ${TEMP_DIR})/${MONGO_DB}

if [ $? -eq 0 ]; then
  echo "‚úÖ MongoDB restore completed"
else
  echo "‚ùå MongoDB restore failed"
  exit 1
fi

# Ï†ïÎ¶¨
rm -rf ${TEMP_DIR}
```

---

## üîß Ïã§Ïäµ 4: Docker Volume Î∞±ÏóÖ

### Step 1: Volume Î∞±ÏóÖ Ïä§ÌÅ¨Î¶ΩÌä∏

```bash
#!/bin/bash
# backup-volumes.sh

VOLUME_NAME=$1
BACKUP_DIR="/backups/volumes"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/${VOLUME_NAME}_${TIMESTAMP}.tar.gz"

if [ -z "$VOLUME_NAME" ]; then
  echo "Usage: $0 <volume_name>"
  exit 1
fi

mkdir -p ${BACKUP_DIR}

# Volume Î∞±ÏóÖ (ÏûÑÏãú Ïª®ÌÖåÏù¥ÎÑà ÏÇ¨Ïö©)
echo "Backing up volume: ${VOLUME_NAME}"
docker run --rm \
  -v ${VOLUME_NAME}:/data \
  -v ${BACKUP_DIR}:/backup \
  alpine \
  tar -czf /backup/$(basename ${BACKUP_FILE}) -C /data .

if [ $? -eq 0 ]; then
  SIZE=$(du -h ${BACKUP_FILE} | cut -f1)
  echo "‚úÖ Volume backup completed: ${BACKUP_FILE} (${SIZE})"
else
  echo "‚ùå Volume backup failed"
  exit 1
fi

# Ïò§ÎûòÎêú Î∞±ÏóÖ ÏÇ≠Ï†ú
find ${BACKUP_DIR} -name "${VOLUME_NAME}_*.tar.gz" -mtime +7 -delete
```

### Step 2: Volume Î≥µÍµ¨

```bash
#!/bin/bash
# restore-volumes.sh

VOLUME_NAME=$1
BACKUP_FILE=$2

if [ -z "$VOLUME_NAME" ] || [ -z "$BACKUP_FILE" ]; then
  echo "Usage: $0 <volume_name> <backup_file>"
  exit 1
fi

# Volume ÏÉùÏÑ± (ÏóÜÏúºÎ©¥)
docker volume create ${VOLUME_NAME}

# Volume Î≥µÍµ¨
echo "Restoring volume: ${VOLUME_NAME}"
docker run --rm \
  -v ${VOLUME_NAME}:/data \
  -v $(dirname ${BACKUP_FILE}):/backup \
  alpine \
  sh -c "cd /data && tar -xzf /backup/$(basename ${BACKUP_FILE})"

if [ $? -eq 0 ]; then
  echo "‚úÖ Volume restore completed"
else
  echo "‚ùå Volume restore failed"
  exit 1
fi
```

---

## üîß Ïã§Ïäµ 5: S3Î°ú ÏõêÍ≤© Î∞±ÏóÖ

### Step 1: S3 ÏóÖÎ°úÎìú Ïä§ÌÅ¨Î¶ΩÌä∏

```bash
#!/bin/bash
# upload-to-s3.sh

AWS_ACCESS_KEY_ID="your-access-key"
AWS_SECRET_ACCESS_KEY="your-secret-key"
S3_BUCKET="my-backup-bucket"
S3_PREFIX="docker-backups"
LOCAL_BACKUP_DIR="/backups"

# AWS CLI ÏÑ§Ïπò ÌôïÏù∏
if ! command -v aws &> /dev/null; then
  echo "Installing AWS CLI..."
  pip install awscli
fi

# S3 ÎèôÍ∏∞Ìôî
echo "Syncing backups to S3..."
aws s3 sync \
  ${LOCAL_BACKUP_DIR} \
  s3://${S3_BUCKET}/${S3_PREFIX} \
  --storage-class STANDARD_IA \
  --delete

if [ $? -eq 0 ]; then
  echo "‚úÖ S3 sync completed"
else
  echo "‚ùå S3 sync failed"
  exit 1
fi

# Lifecycle Policy (ÏÑ†ÌÉù)
# S3ÏóêÏÑú ÏûêÎèôÏúºÎ°ú:
# - 30Ïùº ÌõÑ GlacierÎ°ú Ïù¥Îèô
# - 90Ïùº ÌõÑ ÏÇ≠Ï†ú
```

### Step 2: Docker Compose with S3 Backup

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    # ... (Ïù¥Ï†Ñ ÏÑ§Ï†ï)

  # Local Backup
  postgres-backup:
    image: postgres:15-alpine
    volumes:
      - ./backup-scripts:/scripts
      - ./backups:/backups
    command: >
      sh -c "
      while true; do
        /scripts/backup-postgres.sh
        sleep 86400
      done
      "

  # S3 Sync
  s3-sync:
    image: amazon/aws-cli
    container_name: s3-sync
    restart: always
    volumes:
      - ./backups:/backups
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=us-east-1
    command: >
      sh -c "
      while true; do
        echo 'Syncing to S3...'
        aws s3 sync /backups s3://my-backup-bucket/docker-backups --delete
        echo 'Next sync in 6 hours'
        sleep 21600
      done
      "
```

---

## üîß Ïã§Ïäµ 6: ÏûêÎèôÌôî Î∞±ÏóÖ ÏãúÏä§ÌÖú (Cron)

### Step 1: Cron Í∏∞Î∞ò Î∞±ÏóÖ

```bash
# crontab -e
# Îß§Ïùº ÏÉàÎ≤Ω 2ÏãúÏóê Î∞±ÏóÖ
0 2 * * * /path/to/backup-postgres.sh >> /var/log/backup.log 2>&1

# Îß§Ï£º ÏùºÏöîÏùº ÏÉàÎ≤Ω 3ÏãúÏóê Full Î∞±ÏóÖ
0 3 * * 0 /path/to/backup-full.sh >> /var/log/backup-full.log 2>&1

# Îß§ 6ÏãúÍ∞ÑÎßàÎã§ S3 ÎèôÍ∏∞Ìôî
0 */6 * * * /path/to/upload-to-s3.sh >> /var/log/s3-sync.log 2>&1
```

### Step 2: Backup Î™®ÎãàÌÑ∞ÎßÅ

```bash
#!/bin/bash
# check-backup.sh

BACKUP_DIR="/backups/postgres"
MAX_AGE_HOURS=24

# ÏµúÍ∑º Î∞±ÏóÖ ÌôïÏù∏
LATEST_BACKUP=$(ls -t ${BACKUP_DIR}/*.sql.gz 2>/dev/null | head -1)

if [ -z "$LATEST_BACKUP" ]; then
  echo "‚ùå No backups found"
  exit 1
fi

# Î∞±ÏóÖ ÎÇòÏù¥ ÌôïÏù∏
BACKUP_AGE=$(( ($(date +%s) - $(stat -f%m "$LATEST_BACKUP")) / 3600 ))

if [ $BACKUP_AGE -gt $MAX_AGE_HOURS ]; then
  echo "‚ö†Ô∏è  Backup is old: ${BACKUP_AGE} hours"
  # Alert (Slack, Email)
  curl -X POST https://hooks.slack.com/services/YOUR/WEBHOOK \
    -d "{\"text\":\"‚ö†Ô∏è Backup is old: ${BACKUP_AGE} hours\"}"
  exit 1
else
  echo "‚úÖ Backup is recent: ${BACKUP_AGE} hours old"
fi

# Î∞±ÏóÖ ÌÅ¨Í∏∞ ÌôïÏù∏
BACKUP_SIZE=$(du -h "$LATEST_BACKUP" | cut -f1)
echo "Backup size: ${BACKUP_SIZE}"
```

---

## üîß Ïã§Ïäµ 7: ÏôÑÏ†ÑÌïú Î∞±ÏóÖ ÏãúÏä§ÌÖú

### Step 1: Ï†ÑÏ≤¥ Docker Compose

```yaml
# docker-compose.backup.yml
version: '3.8'

services:
  # Application
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    restart: always
    environment:
      POSTGRES_DB: mydb
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - app

  backend:
    build: ./backend
    container_name: backend
    restart: always
    depends_on:
      - postgres
    networks:
      - app

  # Backup Services
  backup-postgres:
    image: postgres:15-alpine
    container_name: backup-postgres
    restart: always
    volumes:
      - ./backup-scripts:/scripts
      - ./backups/postgres:/backups/postgres
    environment:
      - DB_HOST=postgres
      - DB_NAME=mydb
      - DB_USER=myuser
      - DB_PASSWORD=mypassword
    command: >
      sh -c "
      while true; do
        echo '[Backup] Starting at' \$(date)
        /scripts/backup-postgres.sh
        /scripts/backup-volumes.sh postgres_data
        echo '[Backup] Completed'
        sleep 86400
      done
      "
    depends_on:
      - postgres
    networks:
      - app

  backup-s3-sync:
    image: amazon/aws-cli
    container_name: backup-s3-sync
    restart: always
    volumes:
      - ./backups:/backups
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=us-east-1
    command: >
      sh -c "
      while true; do
        echo '[S3] Syncing backups at' \$(date)
        aws s3 sync /backups s3://my-backup-bucket/backups \
          --storage-class STANDARD_IA \
          --delete
        echo '[S3] Next sync in 6 hours'
        sleep 21600
      done
      "

  backup-monitor:
    image: alpine
    container_name: backup-monitor
    restart: always
    volumes:
      - ./backup-scripts:/scripts
      - ./backups:/backups
    command: >
      sh -c "
      apk add --no-cache curl
      while true; do
        echo '[Monitor] Checking backups at' \$(date)
        /scripts/check-backup.sh
        sleep 3600
      done
      "

volumes:
  postgres_data:

networks:
  app:
    driver: bridge
```

### Step 2: Î∞±ÏóÖ Î≥µÍµ¨ ÌÖåÏä§Ìä∏

```bash
# test-restore.sh
#!/bin/bash

echo "=== Backup & Restore Test ==="

# 1. ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±
echo "Creating test data..."
docker exec postgres psql -U myuser -d mydb -c "CREATE TABLE test (id SERIAL, value TEXT);"
docker exec postgres psql -U myuser -d mydb -c "INSERT INTO test (value) VALUES ('test1'), ('test2'), ('test3');"

# 2. Î∞±ÏóÖ Ïã§Ìñâ
echo "Running backup..."
./backup-scripts/backup-postgres.sh

# 3. Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú
echo "Deleting test data..."
docker exec postgres psql -U myuser -d mydb -c "DROP TABLE test;"

# 4. Î∞±ÏóÖ Î≥µÍµ¨
echo "Restoring from backup..."
LATEST_BACKUP=$(ls -t backups/postgres/*.sql.gz | head -1)
./backup-scripts/restore-postgres.sh ${LATEST_BACKUP}

# 5. Í≤ÄÏ¶ù
echo "Verifying restore..."
RESULT=$(docker exec postgres psql -U myuser -d mydb -t -c "SELECT COUNT(*) FROM test;")

if [ "$RESULT" -eq 3 ]; then
  echo "‚úÖ Restore test passed"
else
  echo "‚ùå Restore test failed"
  exit 1
fi

# 6. Ï†ïÎ¶¨
docker exec postgres psql -U myuser -d mydb -c "DROP TABLE test;"
echo "‚úÖ Test completed"
```

---

## üí° Î∞±ÏóÖ Ï†ÑÎûµ Ï†ïÎ¶¨

```
Backup Schedule:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Î∞±ÏóÖ ÌÉÄÏûÖ        ‚îÇ Ï£ºÍ∏∞      ‚îÇ Î≥¥Ï°¥ Í∏∞Í∞Ñ   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Full Backup     ‚îÇ Îß§Ï£º      ‚îÇ 4Ï£º        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Daily Backup    ‚îÇ Îß§Ïùº      ‚îÇ 7Ïùº        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Hourly Snapshot ‚îÇ Îß§ÏãúÍ∞Ñ    ‚îÇ 24ÏãúÍ∞Ñ     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Cloud Sync      ‚îÇ 6ÏãúÍ∞ÑÎßàÎã§ ‚îÇ 90Ïùº       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Backup Checklist:
‚úÖ ÏûêÎèôÌôî (Cron, Scheduler)
‚úÖ ÏïïÏ∂ï (gzip)
‚úÖ ÏïîÌò∏Ìôî (GPG, ÏÑ†ÌÉù)
‚úÖ ÏõêÍ≤© Ï†ÄÏû• (S3, GCS)
‚úÖ Ï†ïÍ∏∞ Î≥µÍµ¨ ÌÖåÏä§Ìä∏
‚úÖ Î™®ÎãàÌÑ∞ÎßÅ Î∞è ÏïåÎ¶º
‚úÖ Î¨∏ÏÑúÌôî (Î≥µÍµ¨ Ï†àÏ∞®)

Recovery Procedures:
1. Î∞±ÏóÖ ÌååÏùº ÌôïÏù∏
2. ÏÑúÎπÑÏä§ Ï§ëÏßÄ (ÏÑ†ÌÉù)
3. Î∞±ÏóÖ Î≥µÍµ¨
4. Í≤ÄÏ¶ù
5. ÏÑúÎπÑÏä§ Ïû¨ÏãúÏûë
```

---

## üìå ÌïµÏã¨ ÏöîÏïΩ

```
Backup System ÌïµÏã¨:
1. 3-2-1 Rule (3 Î≥µÏÇ¨Î≥∏, 2 ÎØ∏ÎîîÏñ¥, 1 Ïò§ÌîÑÏÇ¨Ïù¥Ìä∏)
2. ÏûêÎèôÌôî (Cron, Scheduler)
3. ÏõêÍ≤© Î∞±ÏóÖ (S3, Cloud)
4. Ï†ïÍ∏∞ ÌÖåÏä§Ìä∏ (Î≥µÍµ¨ Í∞ÄÎä•ÌïúÏßÄ ÌôïÏù∏)
5. Î™®ÎãàÌÑ∞ÎßÅ Î∞è ÏïåÎ¶º

Best Practices:
‚úÖ ÏùºÏùº Î∞±ÏóÖ (ÏµúÏÜå)
‚úÖ ÏïïÏ∂ï Î∞è ÏïîÌò∏Ìôî
‚úÖ Ïò§ÎûòÎêú Î∞±ÏóÖ ÏûêÎèô ÏÇ≠Ï†ú
‚úÖ S3 Glacier (Ïû•Í∏∞ Î≥¥Í¥Ä)
‚úÖ Ï†ïÍ∏∞ Î≥µÍµ¨ ÌÖåÏä§Ìä∏ (Ïõî 1Ìöå)
‚úÖ Î¨∏ÏÑúÌôîÎêú Î≥µÍµ¨ Ï†àÏ∞®
```

---

## üìö Ï∞∏Í≥† ÏûêÎ£å

- [PostgreSQL Backup Documentation](https://www.postgresql.org/docs/current/backup.html)
- [MySQL Backup Strategies](https://dev.mysql.com/doc/refman/8.0/en/backup-and-recovery.html)
- [MongoDB Backup Methods](https://www.mongodb.com/docs/manual/core/backups/)
- [Docker Volume Backup](https://docs.docker.com/storage/volumes/#back-up-restore-or-migrate-data-volumes)
- [3-2-1 Backup Rule](https://www.backblaze.com/blog/the-3-2-1-backup-strategy/)

---

## ü§î ÏÉùÍ∞ÅÌï¥Î≥º Î¨∏Ï†ú

1. Î∞±ÏóÖÏùÄ ÏñºÎßàÎÇò ÏûêÏ£º Ìï¥Ïïº ÌïòÎäîÍ∞Ä?
2. Î∞±ÏóÖÏùÑ ÌÖåÏä§Ìä∏ÌïòÏßÄ ÏïäÏúºÎ©¥ Ïñ¥ÎñªÍ≤å ÎêòÎäîÍ∞Ä?
3. ÌÅ¥ÎùºÏö∞Îìú Î∞±ÏóÖÎßåÏúºÎ°ú Ï∂©Î∂ÑÌïúÍ∞Ä?

> üí° **ÎãµÎ≥Ä**:
> 
> **1) Î∞±ÏóÖ Ï£ºÍ∏∞:**
> 
> ```
> RPO (Recovery Point Objective)Ïóê Îî∞Îùº Í≤∞Ï†ï
> 
> RPO = ÏÜêÏã§ Í∞ÄÎä•Ìïú ÏµúÎåÄ Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞Ñ
> 
> Î∞±ÏóÖ Ï£ºÍ∏∞Î≥Ñ RPO:
> 
> 1ÏãúÍ∞ÑÎßàÎã§:
> - RPO: 1ÏãúÍ∞Ñ
> - Îç∞Ïù¥ÌÑ∞ ÏÜêÏã§: ÏµúÎåÄ 1ÏãúÍ∞Ñ
> - Ïö©ÎèÑ: ÎØ∏ÏÖò ÌÅ¨Î¶¨Ìã∞Ïª¨ (ÏùÄÌñâ, Í±∞ÎûòÏÜå)
> - ÎπÑÏö©: Îß§Ïö∞ ÎÜíÏùå
> 
> 6ÏãúÍ∞ÑÎßàÎã§:
> - RPO: 6ÏãúÍ∞Ñ
> - Ïö©ÎèÑ: Ï§ëÏöî ÏÑúÎπÑÏä§ (Ï†ÑÏûêÏÉÅÍ±∞Îûò)
> - ÎπÑÏö©: ÎÜíÏùå
> 
> ÏùºÏùº (Îß§Ïùº ÏÉàÎ≤Ω 2Ïãú):
> - RPO: 24ÏãúÍ∞Ñ
> - Ïö©ÎèÑ: ÏùºÎ∞ò ÏÑúÎπÑÏä§ (ÎåÄÎ∂ÄÎ∂Ñ)
> - ÎπÑÏö©: Ï§ëÍ∞Ñ
> 
> Ï£ºÍ∞Ñ:
> - RPO: 7Ïùº
> - Ïö©ÎèÑ: Ï†ïÏ†Å Îç∞Ïù¥ÌÑ∞, Î≥¥Í¥ÄÏö©
> - ÎπÑÏö©: ÎÇÆÏùå
> 
> Ïã§Ï†Ñ Ï†ÑÎûµ:
> 
> Tier 1 (Critical):
> - Ìä∏ÎûúÏû≠ÏÖò DB
> - 1-6ÏãúÍ∞ÑÎßàÎã§
> - Ïã§ÏãúÍ∞Ñ Î≥µÏ†ú + Î∞±ÏóÖ
> 
> Tier 2 (Important):
> - ÏÇ¨Ïö©Ïûê Îç∞Ïù¥ÌÑ∞
> - ÏùºÏùº Î∞±ÏóÖ
> - Ï£ºÍ∞Ñ Full + ÏùºÏùº Incremental
> 
> Tier 3 (Normal):
> - Î°úÍ∑∏, ÏûÑÏãú Îç∞Ïù¥ÌÑ∞
> - Ï£ºÍ∞Ñ Î∞±ÏóÖ
> - ÎòêÎäî Î∞±ÏóÖ Ïïà Ìï®
> 
> Î∞±ÏóÖ ÌÉÄÏûÖ:
> 
> Full Backup (Ï£º 1Ìöå):
> - Î™®Îì† Îç∞Ïù¥ÌÑ∞
> - ÏùºÏöîÏùº ÏÉàÎ≤Ω 2Ïãú
> - Î≥µÍµ¨ Îπ†Î¶Ñ
> - Ïä§ÌÜ†Î¶¨ÏßÄ ÎßéÏù¥ ÏÇ¨Ïö©
> 
> Incremental (Ïùº 6Ìöå):
> - Î≥ÄÍ≤ΩÎêú Í≤ÉÎßå
> - 4ÏãúÍ∞ÑÎßàÎã§
> - Î≥µÍµ¨ ÎäêÎ¶º (Full + Î™®Îì† Incremental)
> - Ïä§ÌÜ†Î¶¨ÏßÄ Ï†ÅÍ≤å ÏÇ¨Ïö©
> 
> Differential (Ïùº 1Ìöå):
> - ÎßàÏßÄÎßâ Full Ïù¥ÌõÑ Î≥ÄÍ≤Ω
> - Îß§Ïùº ÏÉàÎ≤Ω 2Ïãú
> - Î≥µÍµ¨ Ï§ëÍ∞Ñ (Full + ÎßàÏßÄÎßâ Differential)
> - Ïä§ÌÜ†Î¶¨ÏßÄ Ï§ëÍ∞Ñ
> 
> Í∂åÏû• Ï°∞Ìï©:
> 
> ÏÜåÍ∑úÎ™®:
> - Full: Îß§Ïùº
> - Î≥¥Ï°¥: 7Ïùº
> 
> Ï§ëÍ∑úÎ™®:
> - Full: Ï£º 1Ìöå (ÏùºÏöîÏùº)
> - Incremental: Îß§Ïùº
> - Î≥¥Ï°¥: 4Ï£º
> 
> ÎåÄÍ∑úÎ™®:
> - Full: Ï£º 1Ìöå
> - Differential: Îß§Ïùº
> - Incremental: 6ÏãúÍ∞ÑÎßàÎã§
> - Î≥¥Ï°¥: 3Í∞úÏõî
> 
> Í≤∞Î°†:
> ÏùºÎ∞ò ÏÑúÎπÑÏä§: ÏùºÏùº Full
> Ï§ëÏöî ÏÑúÎπÑÏä§: 6ÏãúÍ∞Ñ Incremental
> ÎØ∏ÏÖò ÌÅ¨Î¶¨Ìã∞Ïª¨: Ïã§ÏãúÍ∞Ñ Î≥µÏ†ú + Î∞±ÏóÖ
> ```
> 
> **2) Î∞±ÏóÖ ÌÖåÏä§Ìä∏ Ïïà ÌïòÎ©¥?**
> 
> ```
> "Î∞±ÏóÖ ÌÖåÏä§Ìä∏ Ïïà Ìïú Î∞±ÏóÖ = Î∞±ÏóÖ ÏóÜÎäî Í≤É"
> 
> Ïã§Ï†ú ÏÇ¨Í≥† ÏÇ¨Î°Ä:
> 
> Case 1: GitLab (2017)
> - Î∞±ÏóÖ ÏûàÏùå
> - Î≥µÍµ¨ Ïä§ÌÅ¨Î¶ΩÌä∏ Î≤ÑÍ∑∏
> - ÌÖåÏä§Ìä∏ Ïïà Ìï®
> ‚Üí 300GB Îç∞Ïù¥ÌÑ∞ ÏÜêÏã§
> ‚Üí 6ÏãúÍ∞Ñ Îã§Ïö¥ÌÉÄÏûÑ
> 
> Case 2: ÏùµÎ™Ö Ïä§ÌÉÄÌä∏ÏóÖ
> - S3Ïóê Î∞±ÏóÖ Ï§ë
> - Í∂åÌïú ÏÑ§Ï†ï Ïò§Î•ò
> - Îπà ÌååÏùº Î∞±ÏóÖÎê®
> - ÌÖåÏä§Ìä∏ Ïïà Ìï®
> ‚Üí Ïã§Ï†ú Î≥µÍµ¨ Ïãú Î∞úÍ≤¨
> ‚Üí Îç∞Ïù¥ÌÑ∞ ÏÜêÏã§
> 
> ÌùîÌïú Ïã§Ìå® ÏõêÏù∏:
> 
> 1. ÌååÏùº ÏÜêÏÉÅ
>    - Î∞±ÏóÖ Ï§ë Ï§ëÎã®
>    - ÎîîÏä§ÌÅ¨ Ïò§Î•ò
>    ‚Üí ÏïïÏ∂ï ÌååÏùº Íπ®Ïßê
> 
> 2. Í∂åÌïú Î¨∏Ï†ú
>    - Î∞±ÏóÖ: root
>    - Î≥µÍµ¨: user
>    ‚Üí Permission Denied
> 
> 3. Î≤ÑÏ†Ñ Î∂àÏùºÏπò
>    - Î∞±ÏóÖ: PostgreSQL 14
>    - Î≥µÍµ¨: PostgreSQL 16
>    ‚Üí Ìò∏Ìôò Ïïà Îê®
> 
> 4. Í≤ΩÎ°ú Î¨∏Ï†ú
>    - Î∞±ÏóÖ: /backup/db.sql
>    - Î≥µÍµ¨: /backup/db.sql ÏóÜÏùå
>    ‚Üí ÌååÏùº Î™ª Ï∞æÏùå
> 
> 5. Ïä§ÌÅ¨Î¶ΩÌä∏ Î≤ÑÍ∑∏
>    - ifÎ¨∏ Ïò§ÌÉÄ
>    - Î≥ÄÏàò Ïò§Î•ò
>    ‚Üí Ïã§Ìñâ Ïïà Îê®
> 
> ÌÖåÏä§Ìä∏ Î∞©Î≤ï:
> 
> Ïõî 1Ìöå Î≥µÍµ¨ ÌÖåÏä§Ìä∏:
> 
> # 1. ÌÖåÏä§Ìä∏ ÌôòÍ≤Ω Ï§ÄÎπÑ
> docker-compose -f docker-compose.test.yml up -d
> 
> # 2. ÏµúÏã† Î∞±ÏóÖ Î≥µÍµ¨
> ./restore.sh backups/latest.sql
> 
> # 3. Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù
> docker exec test-db psql -c "SELECT COUNT(*) FROM users"
> 
> # 4. Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò ÌÖåÏä§Ìä∏
> curl http://test-backend/api/users
> 
> # 5. Ï†ïÎ¶¨
> docker-compose -f docker-compose.test.yml down
> 
> ÏûêÎèôÌôî:
> 
> # cron (Îß§Ïõî 1Ïùº 3Ïãú)
> 0 3 1 * * /scripts/backup-test.sh
> 
> # backup-test.sh
> #!/bin/bash
> restore_and_test() {
>   # Î≥µÍµ¨
>   ./restore.sh $LATEST_BACKUP
>   
>   # ÌÖåÏä§Ìä∏
>   test_result=$(run_tests)
>   
>   if [ $? -eq 0 ]; then
>     notify_slack "‚úÖ Backup test passed"
>   else
>     notify_slack "‚ùå Backup test FAILED"
>     notify_pagerduty
>   fi
> }
> 
> Î©îÌä∏Î¶≠:
> - Last Backup Test: 2024-01-15
> - Test Result: PASS
> - Recovery Time: 5 minutes
> - Data Integrity: 100%
> 
> Í≤∞Î°†:
> Î∞±ÏóÖ != Î≥µÍµ¨ Í∞ÄÎä•
> Ïõî 1Ìöå Î≥µÍµ¨ ÌÖåÏä§Ìä∏ ÌïÑÏàò
> ÏûêÎèôÌôî + ÏïåÎ¶º
> "ÌÖåÏä§Ìä∏ Ïïà Ìïú Î∞±ÏóÖÏùÄ Î¨¥Ïö©ÏßÄÎ¨º"
> ```
> 
> **3) ÌÅ¥ÎùºÏö∞Îìú Î∞±ÏóÖÎßåÏúºÎ°ú?**
> 
> ```
> NO! 3-2-1 Rule Îî∞ÎùºÏïº
> 
> 3-2-1 Backup Rule:
> 
> 3: Îç∞Ïù¥ÌÑ∞ 3Í∞ú Î≥µÏÇ¨Î≥∏
> - Original (Ïö¥ÏòÅ ÏÑúÎ≤Ñ)
> - Local Backup (Î°úÏª¨ ÏÑúÎ≤Ñ/NAS)
> - Remote Backup (ÌÅ¥ÎùºÏö∞Îìú)
> 
> 2: 2Í∞ú Îã§Î•∏ ÎØ∏ÎîîÏñ¥
> - Disk (SSD/HDD)
> - Cloud (S3/GCS)
> 
> 1: 1Í∞ú Ïò§ÌîÑÏÇ¨Ïù¥Ìä∏ (ÏõêÍ≤©ÏßÄ)
> - Îã§Î•∏ ÏßÄÏó≠/Îç∞Ïù¥ÌÑ∞ÏÑºÌÑ∞
> - Ïû¨Ìï¥ ÎåÄÎπÑ
> 
> ÌÅ¥ÎùºÏö∞ÎìúÎßåÏùò ÏúÑÌóò:
> 
> 1. Í≥ÑÏ†ï Ìï¥ÌÇπ
>    - AWS Í≥ÑÏ†ï ÌÉàÏ∑®
>    - Î∞±ÏóÖ ÏÇ≠Ï†ú
>    ‚Üí Î™®Îì† Î∞±ÏóÖ ÏÜåÏã§
> 
> 2. Ïã§Ïàò ÏÇ≠Ï†ú
>    - aws s3 rm --recursive
>    - Î≥µÍµ¨ Î∂àÍ∞Ä (versioning ÏóÜÏúºÎ©¥)
> 
> 3. ÏÑúÎπÑÏä§ Ïû•Ïï†
>    - AWS S3 Îã§Ïö¥ (2017ÎÖÑ Ïã§Ï†ú Î∞úÏÉù)
>    - Ï†ëÍ∑º Î∂àÍ∞Ä
>    ‚Üí Î≥µÍµ¨ Î∂àÍ∞Ä
> 
> 4. ÎπÑÏö© Î¨∏Ï†ú
>    - ÎØ∏ÎÇ©
>    - Í≥ÑÏ†ï Ï†ïÏßÄ
>    ‚Üí Î∞±ÏóÖ ÏÇ≠Ï†ú
> 
> 5. Í∑úÏ†ï ÏúÑÎ∞ò
>    - GDPR (EU Îç∞Ïù¥ÌÑ∞ EU Ï†ÄÏû•)
>    - Íµ≠ÎÇ¥Î≤ï (Í∞úÏù∏Ï†ïÎ≥¥ Íµ≠ÎÇ¥ Ï†ÄÏû•)
>    ‚Üí ÌÅ¥ÎùºÏö∞ÎìúÎßåÏúºÎ°ú Î∂ÄÏ°±
> 
> Ïò¨Î∞îÎ•∏ Ï†ÑÎûµ:
> 
> Local (Îπ†Î•∏ Î≥µÍµ¨):
> - NAS/Server
> - 7Ïùº Î≥¥Í¥Ä
> - RPO: 1Ïùº
> - RTO: 10Î∂Ñ
> 
> Cloud (Ïû•Í∏∞ Î≥¥Í¥Ä):
> - S3/GCS
> - 90Ïùº Î≥¥Í¥Ä
> - RPO: 1Ïùº
> - RTO: 1ÏãúÍ∞Ñ
> 
> Multi-Cloud (Ïû¨Ìï¥ ÎåÄÎπÑ):
> - S3 + GCS
> - 1ÎÖÑ Î≥¥Í¥Ä
> - RPO: 1Ï£º
> - RTO: 1Ïùº
> 
> Ïã§Ï†Ñ Íµ¨ÏÑ±:
> 
> 1. ÏùºÏùº Î∞±ÏóÖ ‚Üí Local NAS
> 2. Local ‚Üí S3 ÎèôÍ∏∞Ìôî (6ÏãúÍ∞ÑÎßàÎã§)
> 3. S3 ‚Üí Glacier (30Ïùº ÌõÑ)
> 4. S3 ‚Üí GCS Î≥µÏ†ú (Ï£º 1Ìöå)
> 
> ÎπÑÏö©:
> Local: $100 (NAS)
> S3: $30/month
> Glacier: $5/month
> GCS: $20/month
> Total: $155/month
> 
> vs ÌÅ¥ÎùºÏö∞ÎìúÎßå:
> S3: $50/month
> 
> ‚Üí $105 Îçî ÎπÑÏã∏ÏßÄÎßå ÏïàÏ†Ñ
> 
> Ïû¨Ìï¥ ÏãúÎÇòÎ¶¨Ïò§:
> 
> ÏãúÎÇòÎ¶¨Ïò§ 1: ÏÑúÎ≤Ñ Í≥†Ïû•
> ‚Üí Local Î∞±ÏóÖÏúºÎ°ú Î≥µÍµ¨ (10Î∂Ñ)
> 
> ÏãúÎÇòÎ¶¨Ïò§ 2: Îç∞Ïù¥ÌÑ∞ÏÑºÌÑ∞ ÌôîÏû¨
> ‚Üí S3 Î∞±ÏóÖÏúºÎ°ú Î≥µÍµ¨ (1ÏãúÍ∞Ñ)
> 
> ÏãúÎÇòÎ¶¨Ïò§ 3: AWS Í≥ÑÏ†ï Ìï¥ÌÇπ
> ‚Üí GCS Î∞±ÏóÖÏúºÎ°ú Î≥µÍµ¨ (1Ïùº)
> 
> ÏãúÎÇòÎ¶¨Ïò§ 4: Ï†Ñ ÏÑ∏Í≥Ñ ÌÅ¥ÎùºÏö∞Îìú Ïû•Ïï†
> ‚Üí Tape/Offline Î∞±ÏóÖ (ÏûàÎã§Î©¥)
> 
> Í≤∞Î°†:
> ÌÅ¥ÎùºÏö∞ÎìúÎßå = ÏúÑÌóò
> 3-2-1 Rule = ÏïàÏ†Ñ
> Local + Multi-Cloud = Best
> ÎπÑÏö© vs ÏïàÏ†ÑÏÑ± Ìä∏Î†àÏù¥ÎìúÏò§ÌîÑ
> ```


---

<div align="center">

**[‚¨ÖÔ∏è Ïù¥Ï†Ñ: Log Aggregation](./05-Log-Aggregation.md)** | **[Îã§Ïùå: Multi-Tier App ‚û°Ô∏è](./07-Multi-Tier-App.md)**

</div>
